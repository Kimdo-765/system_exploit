Heap Exploitation glibc version 2.25 it is based on how2heap + a

0. heap
	1. Chunk
		a. Allocated chunk : prev_size | Size of chunk | Data | Size of next chunk
		b. Free chunk : Chunk | Chunk size | fd | bk | Unused Space | Size of next chunk ( main_arena <bk---fd> chunk1 <bk---fd> chunk2 <bk---fd> main_arena )
		c. Top chunk : the last in the memory, resized when malloc asks for more space from the os
	2. Bin
		a. Fast bin : P.fd == next_chunk.prev_size, 0x10~0x58 bytes(0x20~0xb0 bytes in x64), 10 bins(single linked list), Free chunk Merge X
		b. Small bin : 0x10~0x1f8(0x20~0x3f0 in x64) bytes, 62 bins(double linked list), Free chunk Merge
		c. Large bin : 0x200~0x3f0(0x400~0x7e0 in x64) bytes, 63 bins(2 double linked list), Free chunk Merge, The fd_nextsize in the large bin chunk points to the first chunk in the list that is smaller than itself, and bk_nextsize points to the first chunk larger than itself.
		d. Unsorted bin : Freed Small, Large chunk, 1 bin(double linked list)
	3. malloc
	4. free : FastChunkSize?FastBin:UnsrotedBin, FastBin,UnsortedBin=>SmallSize?SmallBin:LargeBin
		a. unlink : prev_inuse?nop:consolidate( P→fd->bk = P→bk; P→bk->fd = P->fd ), bin[x] => [a] <bk---fd> [b] <bk---fd> [c] in this situation consolidated [b+d] must move to bin[x+i], so do unlink() 

		
1. House of Force - Overwrite Top Chunk
	1. Conditions
		a.  1 malloc(size) #A( Writable, overflow to top_chunk.size )
		b.  1 malloc(evil_size) #B( We have to control size ) 
		c.  1 malloc(Size) #C( Writable )
	2. Exploit
		a. malloc(size) #A : set up memory
		b. *(A+real_A_size) = 0xffffffffffffffff : top_chunk.size = 0xffffffffffffffff, Now, malloc will never call mmap
		c. malloc(evil_size) #B : evil_size = target - old_top - 2*2*SIZE_SZ : Now, new_top = dest - 2*sizeof(long)
		e. malloc(Size) #C : new_top is allocated
	3. Value
		a. Manipulate data at semi-arbitary memory (higher address than top_chunk)


2. House of Spirit - Fake Chunk to Fast Bin
	1. Conditions
		a. 2 stack buffer : #A <---we can overwrite here, fast chunk size---> #B
		b. 1 malloc(any) : set up memory
		c. 1 free(A)
		d. 1 malloc(A to B - header_size)
	2. Exploit
		a. malloc(any) : set up memory
		b. fake_chunk1.size = size : fake_chunk1 + size == fake_chunk2
		c. fake_chunk2.size = Size : Size > 2*SIZE_SZ && Size < av->system_mem
		d. free(fake_chunk1 + 0x10) : FastBin => fake_chunk1
		e. malloc(fake_chunk1.size - 2*SIZE_SZ) : malloc at fake_chunk1
	3. Value
		a. Make buffer overflow attack vector
		
		
3. House of Lore - Bypass Small Bin Corrupted( bck->fd != victim )
	1. Conditions
		a. 2 stack buffer #fake_chunk1( writable, size >= 4*SIZE_SZ ), #fake_chunk2( writable, size >= SIZE_SZ )
		b. 3 malloc(small_bin_size) #A( writable after free ), #B, #C( writable )
		c. 1 malloc(large_bin_size)
		d. 1 free(A)
	2. Exploit
		a. malloc(small_chunk_size) #A
		b. fake_chunk1.prev_size = 0, fake_chunk1.size = 0, fake_chunk1.fd = A - 2*SIZE_SZ, fake_chunk1.bk = fake_chunk2, fake_chunk2.fd = fake_chunk1 : fake_chunk2 <bk---fd> fake_chunk1 <---fd> A
		c. malloc(large_chunk_size) : prevent consolidating the top chunk with A
		d. free(A) : UnsortedBin => A
		e. malloc(larger_than_A) : SmallBin => fake_chunk2 <bk---fd> fake_chunk1 <---fd> A <bk---fd> main_arena
		f. A.bk = fake_chunk1 : SmallBin => fake_chunk2 <bk---fd> fake_chunk1 <bk---fd> A <bk---fd> main_arena
		g. malloc(Size.A - 2*SIZE_SZ) #B : SmallBin => fake_chunk2 <bk---fd> fake_chunk1 <bk---fd> main_arena
		h. malloc(Size.A - 2*SIZE_SZ) #C : fake_chunk1 is allocated, SmallBin => fake_chunk2 <bk---fd> main_arena

	3. Value
		a. Make buffer overflow attack vector
		
		
4. first fit - UAF
	1. Conditions
		a. 2 malloc(size) #A( writable after free), #B( non-writable )
		b. 1 free(A) 
	2. Exploit
		a. malloc(size) #A
		a. free(A)
		b. malloc(size) #B : A == B, we can control B via A
	3. Value
		a. Manipulate heap data via duplicate heap pointer
		

5. fastbin dup - DFB
	1. Conditions
		a. 3 malloc(fast_chunk_size) #A, #B, #C 
		b. free(A), free(B), free(A)
		c. 3 malloc(fast_chunk_size)
	2. Exploit
		a. 3 malloc(fast_chunk_size) #A, #B, #C : C for preventing consolidating top chunk with B
		b. free(A) : FastBin => A ---fd> main_arena
		c. free(B) : FastBin => B ---fd> A ---fd> main_arena 
		d. free(A) : FastBin => A ---fd> B ---fd> A ---fd> B ...
		e. 3 malloc(A.size - 2*SIZE_SZ) : allocated A, B, A. A is duplicated
	3. Value
		a. Manipulate heap data via Duplicate heap pointer
		
		
6. fasetbin dup into stack
	1. Conditions
		a. 1 stack buffer #fake_chunk( size >= SIZE_SZ )
		b. 3 malloc(fast_chunk_size) #A, #B, #C
		c. free(A), free(B), free(A)
		d. 2 malloc(fast_chunk_size) #D( writable ), #E 
		e. 2 malloc(fast_chunk_size)
	2. Exploit
		a. 3 malloc(fast_chunk_size) #A, #B, #C : C for preventing consolidating top chunk with B
		b. free(A) -> free(B) -> free(A) : build up fastbin_dup
		c. 2 malloc(A.size - 2*SIZE_SZ) #D, #E : A and B is allocated, FastBin => A ---fd> B ---fd> A ...
		d. fake_chunk.size = A.size, D.fd = fake_chunk : FastBin A ---fd> fake_chunk ---x>
		e. 2 malloc(A.size -2*SIZE_SZ) : A and fake_chunk is allocated
	3. Value
		a. Make buffer overflow attack vector


7. House of einherjar - off by one
	1. Conditions
		a. 1 buffer #fake_chunk( size >= 6*SIZE_SZ )
		b. 2 malloc(size) #A( writable, off by one to B.size.prev_inuse ), #B
		c. free(B)
		d. malloc(Size)
	2. Exploit
		a. 2 malloc(size) #A, #B
		b. fake_chunk.prev_size = ANY, fake_chunk.size = ANY, fake_chunk.fd = fake_chunk, fake_chunk.bk = fake_chunk, fake_chunk.fd_nextsize = fake_chunk, fake_chunk.bk_nextsize = fake_chunk
		c. *(A+real_A_size - SIZE_SZ) = (B - 2*SIZE_SZ) - fake_chunk, *(A+real_A_size) = 0 : B.prev_size = -(B to fake_chunk), B.size = B.size | 0xff00, via off by one
		d. fake_chunk.size = B.prev_size : bypass "unlink : corrupted size vs. prev_size"
		e. free(B) : 
			1. If B is top chunk( malloc(C) before free(B) ) : fake_chunk & B & top_chunk are consolidated, unlink fake_chunk, new_top == fake_chunk
				a. malloc(Size) : fake_chunk is allocated
			2. If B is not top chunk : fake_chunk & B are consolidated, unlink fake_chunk, UnsortedBin => fake_chunk
				a. fake_chunk.size = SIZE, 2*SIZE_SZ <= SIZE <= av->system_mem : bypass " malloc() : memory corruption"
				b. malloc(Size) : fake_chunk is allocated
	3. Value
		a. Make buffer overflow attack vector
		
		
8. Poison null byte - off by one
	1. Conditions
		a. 4 malloc(any) #A( writable, off by one to B.size ), #B( writable ), #C, #D
		b. free
	2. Exploit
		a. 4 malloc(any) #A, #B, #C, #D : D for preventing consolidating top chunk with C
		b. free(B) : UnsortedBin => B, C.prev_size = B.size, C.size.prev_inuse = 0
		d. *(A+real_A_size) = 0 : B.size = B.size|0xff00
		c. *(B + B.size|0xff00 - 2*SIZE_SZ) = B.size|0xff00 : fake_C_prevsize = B.size|0xff00, fake_C_prevsize == B.size, bypass "unlink : corrupted size vs. prev_size"
		e. malloc(smaller_than_B) #B1 : C.prev_size is not changed, B is allocated, unlink B, (B.size - B1.size)UnsortedBin => remain_B
		f. malloc(smaller_than_B1) #B2 : C.prev_size is not changed, B+B1.size is allocated, unlink remain_B, (B.size - B1.size - B2.size)UnsortedBin => remain2_B
		g. free(B1) : (B1.size)UnsortedBin => B2
		h. free(C) : C.prev_chunk == C - C.prev_size == B1, B1 and C are consolidated, unlink B1, (C.prev_size + C.size)UnsortedBin => B1
		i. malloc(C.prev_size + C.size - 2*SIZE_SZ) : B1 is allocated, overlapping B2
	3. Value
		a. Manipulate heap data via overlapping


9. Overlapping chunks
	1. Conditions
		a. [ 3 malloc() #A( writable, BOF to B.size ), #B, #C ]
		b. [ free(B) ]
		c. [ malloc(Size) ]
	2. Exploit 
		a. 3 malloc() #A, #B, #C
		b. free(B)
		c. Overwrite B.size = B.size + C.size + prev_inuse(1) : B.next_chunk => Top_chunk
		d. malloc(B.size) : Overwrite C
	3. Value
		a. Manipulate heap data


10. Overlapping chunks 2
	1. Conditions
		a. [ 5 malloc() #A( writable, BOF to B.size ), #B, #C, #D, #E ]
		b. [ free(D) ]
		c. [ malloc(Size) ]
	2. Exploit
		a. 5 malloc() #A, #B, #C, #D, #E
		b. free(D)
		c. Overwrite B.size = B.size + C.size + prev_inuse(1) : B.next_chunk => D
		d. free(B) : D.prev_size = B.size + C.size
		e. malloc(Size) : Size= B.size + C.size => Overwrite C
	3. Value
		a. Manipulate heap data
		
		
11. unsorted bin attack
	1. Conditions
		a. [ 2 malloc(small_chunk) #A( writable after free ), #B ]
		b. [ free(A) ]
		c. [ malloc(small_chunk) ]
	2. Exploit 
		a. 2 malooc(fast_chunk) #A, #B
		b. free(A)
		c. Overwrite A.bk = victim - 0x8|0x10
		d. malloc(Size) : Size = A.size - header_size => *(victim) = prev_size, *(victim+0x8) = size,...
	3. Value
		a. if(false){ByPass}Runthis
		
		
12. House of Orange
	1. Conditions
		a. [ malloc() #A( writable, BOF to &top_chunk + 0xc0 ), #B( Very_big_size ), #C( 0x10 ) ]
	2. Exploit 
		a. malloc(Size) #A : Size = small_bin or large_bin
		b. Top_Chunk.size = Top_Chunk.size - PAGE_SIZE * n + 0x1 : e.g) 0x20c01 to 0xc01
		c. malloc(Size) #B : Size = Very_big_size : sysmalloc & _int_free is invoked, now new top chunk allocated and Unsorted_bin = prev_top_chunk
		d. Overwrite prev_top_chunk.prev_size = "/bin/sh", prev_top_chunk.size = size_small_chunk[4], prev_top_chunk.bk = &_IO_list_all - 0x10 
		e. Make fake_fp @ prev_top_chunk to trigger _IO_OVERFLOW
			1. fp->_mode = 0 : &free_chunk + 0xc0
			2. fp->_IO_write_base = 2 : &free_chunk + 0x20
			3. fp->_IO_write_ptr = 3 : &free_chunk + 0x28
			4. _IO_jump_t[3] = &system() : jump_table = &controlled_momory, jump_table[3] = &system, jump_*(&prev_top_chunk + 0xd8) = &jump_table
		f. malloc(10) : _IO_list_all = <main_arena+88> => prev_top_chunk is switched to smallbin[4] => smallbin[4] is <main_arena+88>+0x68(*_chain in _IO_list_all) => _int_malloc detect memory corruption "size <= 2 * SIZE_SZ" => call _IO_OVERFLOW() : system("/bin/sh")
	3. Value
		a. Execute arbitary function
		

13. unsafe unlink
	1. Conditions
		a. [ 2 malloc[0x80] #A( writable, BOF to B.size ), #B ]
		b. [ free(B) ]
		c. [ global pointer buf1( writable through pointer ) ]
	2. Exploit
		a. 2 malloc(0x80) #A, #B
		b. global buf1 = &A 
		c. Create Fake Chunk, (&A + 0x10) = 0x0, (&A + 0x18) = 0x0, (&A + 0x20) = &buf1 - 0x18, (&A + 0x28) = &buf - 0x10 : P.next_chunk = P, P->fd->bk == P, P->bk->fd == P
		d. B.prev_size = 0x80, B.size = 0x90 (delete prev_inuse)
		e. free(B) : consolidate works, buf1 = fake_chunk.fd(&buf1 - 0x18)
		f. Overwrite buf1 : *buf1 = "A"*0x18 + target_address, e.g) GOT
		g. Overwrite target_address : *buf1 = something, e.g) &system
	3. Value
		a. Manipulate ANY memory that is writable to arbitary data
		
		
14. large bin attack
	1. Conditions
		a.
	2. Exploit
		a. malloc(large_chunk) #A
		b. malloc(fast_chunk) : prevent consolidating #A with #B
		c. malloc(large_chunk.larger_than_A) #B
		d. malloc(fast_chunk) : prevent consolidating #B with #C
		e. malloc(B.size - header_size) #C
		f. malloc(fast_chunk) : prevent consolidating #C with top chunk
		g. free(A), free(B) : unsorted bin [ B <---> A ]
		h. malloc(size <= A.size) #D : B is moved to large bin freelist, parts of A is allocated and the remaining of the freed firtst large chunk into the unsorted bin[ &A + d.size + header_size ], large bin[ B ]
		i. free(C) : unsorted bin [ C <---> &A + D.size + header_size ], large bin[ B ]
		j. B.size = large_chunk.smaller_than_A, B.fd = 0, B.bk = target_address1 - 0x10, B.fd_nextsize = 0, B.bk_nextsize = target_address2 - 0x20
		k. malloc(D.size) : large bin [ target_address1 - 0x10 <bk--- B ] => [ C <bk--- target_address - 0x10 <bk--- B ], target_address1 = &C, target_address2 = &C
	3. Value
		a. Manipulate ANY momory that is writable to &C
